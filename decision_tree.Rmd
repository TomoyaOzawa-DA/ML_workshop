---
title: "Titanic Prediction: Decision tree"
author: "Tomoya Ozawa"
date: "`r format(Sys.time(), '%Y/%m/%d')`"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("caret")) install.packages("caret")
if (!require("rpart")) install.packages("rpart")
if (!require("rpart.plot")) install.packages("rpart.plot")
if (!require("partykit")) install.packages("partykit")
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(partykit)
```

## 0. はじめに
### 0.1. 目的

- タイタニックの生存者を予測します。

### 0.2. 使用するデータ

- タイタニック号の搭乗者に関するデータです。1行が搭乗者1名の情報になっています。
- [こちら](https://www.kaggle.com/c/titanic/data)からダウンロードしてください。
  - `train.csv`: 生存したかどうかがわかっている搭乗者のデータ。このデータを使って、どんな人が生存している傾向にあるのかをモデルにしていきます。
  - `test.csv`: 今回生存したかどうかを予測したい搭乗者のデータ

### 0.3. 機械学習モデル構築の流れ

1. データの把握
2. データの加工
3. モデル構築
4. モデルの評価


## 1. データの把握

- まずはデータを読み込みます
```{r}
df <- read.csv("titanic/train.csv")
```

- データを確認してみます。今回のタスクは`Survived`が0 or 1かを予測することです。
```{r}
head(df)
```

- 変数の定義

|  変数  |  定義  |
| ---- | ---- |
|  PassengerId  |  乗客に紐づけられたID  |
|  Survived  |  生還した人は1, しなかったら0  |
|  Pclass  |  旅券の種類, 1: 1st, 2: 2nd, 3: 3rd  |
|  Name  |  名前  |
|  Sex  |  性別  |
|  Age  |  年齢  |
|  SibSp  |  一緒に乗船した兄弟、配偶者の数  |
| Parch  |  一緒に乗船した両親、子供の数  |
|  Ticket  |  旅券の番号  |
|  Fare  |  乗船料金  |
|  Cabin  |  部屋番号  |
| Embarked  |  乗船した港  |

- データの行数と列数を確認します。
```{r}
dim(df)
```


- 数値に関しては基本統計量を確認してみます。
```{r}
summary(df)
```

- カテゴリ変数については、ユニークな値を確認して、それらの頻度をみます。
```{r}
df %>% 
  count(Embarked)
```


- どのくらいの人が生存しているのか？どんな人が生存している傾向にあるのかを可視化して確認してみます。
```{r}
df %>% 
  count(Survived)
```
- `train.csv`では38%くらい生存している。
```{r}
df_age_survived <- df %>% 
  group_by(Sex, Survived) %>% 
  summarise(Freq = n(), .groups= "drop")
df_age_survived
```

```{r}
ggplot(data = df_age_survived, aes(x = Sex, y = Freq, fill = as.factor(Survived))) +
  geom_bar(stat = "identity", position = "dodge")
```

- 女性の方が生存している割合が高そうです。

### Groupwork 1

- 他の変数について確認してみましょう。

## 2. データの加工

- `age`列に欠損値がありますね。
```{r}
summary(df)
```

- 欠損値がある場合は、まずどうして欠損が生じているのか？を考えます。その上で、以下のアプローチを取ることが多いです。
  - 欠損が生じるパターンがあれば、それを考慮してて適切な値を埋める。（例えば、20才未満の人たちはNAになっているとか。）
  - 平均値や中央値で埋める
  - 欠損値の値に推定値を使う
  - 欠損値を含む行を分析に使わない
- 今回は簡略化のために、欠損を含む行は分析に使わないことにします。

```{r}
df <- na.omit(df)
```

- データを訓練データと検証データに分けます。
  - 訓練データ: モデル構築に使用するデータ
  - 検証データ: モデルの性能を評価するためのデータ
```{r}
set.seed(123)
ind_train <- createDataPartition(y = df$Survived, p = 0.7,list = FALSE)
df_train <- df[ind_train,]
df_valid <- df[-ind_train,]
```


## 3. モデル構築

- `Pclass`, `Age`, `SibSp`, `Parch`, `Fare`の値を用いて、`Survived`を予測してみます。

```{r}
tree <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare , 
              data=df_train, maxdepth=3, method = "class")
```

- `maxdepth`は木の深さを表します。他にもハイパーパラメータは存在しますが、今回は`maxdepth`をいじってみます。

```{r}
rpart.plot(tree)
```



## 4. モデルの評価

- 訓練用データに対するフィット
```{r}
df_train$Survived_pred <- predict(tree, df_train, type="class")
```

- 混同行列
```{r}
result_train <- table(df_train$Survived, df_train$Survived_pred)
result_train
```

- 正解率を計算する
```{r}
accuracy_train <- sum(diag(result_train)) / sum(result_train)
accuracy_train
```


- 未知のデータ（検証データ）に対するフィット
```{r}
df_valid$Survived_pred <- predict(tree, df_valid, type="class")
```

- 混同行列
```{r}
result_valid <- table(df_valid$Survived, df_valid$Survived_pred)
result_valid
```

- 正解率を計算する
```{r}
accuracy_valid <- sum(diag(result_valid)) / sum(result_valid)
accuracy_valid
```

- モデル構築にて、`maxdepth`の値を大きくする（例えば`3` -> `8`にする）と、df_trainの正解率は向上するが、df_validの正解率は悪化することを確認することが出来る。この状態を**過学習**と呼ぶ。手元のデータに過剰適合してしまい、本来の目的である未知のデータに対する予測精度が悪化してしまう。

- 変数の重要度（枝分けにどの程度貢献しているか）を見ると、どの変数が0, 1の分類に重要なのかを把握出来ます。
```{r}
tree$variable.importance
```


### Groupwork2

- `maxdepth`を8にして、訓練用データと検証用データへのフィットを確認してみましょう



# 5. おまけ

- ロジットモデルとの比較

```{r}
logit <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare, family = binomial(link = "logit"),
             data=df_train)
```

```{r}
summary(logit)
```

```{r}
df_train$Survived_pred_logit <- predict(logit, df_train, type = "response")
```

```{r}
df_train <- df_train %>% mutate(Survived_pred_logit = if_else(Survived_pred_logit > 0.5, "1", "0"))
```

```{r}
result_train_logit <- table(df_train$Survived, df_train$Survived_pred_logit)
result_train_logit
```


```{r}
accuracy_train_logit <- sum(diag(result_train_logit)) / sum(result_train_logit)
accuracy_train_logit
```


- Kaggleにsubmitする時


```{r}
df_test <- read.csv("titanic/test.csv") 
df_test <- df_test %>% 
  replace_na(list(Age = median(df_test$Age, na.rm = TRUE), 
                  Fare = mean(df_test$Fare, na.rm = TRUE)))
```


```{r}
# decision tree maxdepth = 3
df_test$Survived <- predict(tree, df_test, type="class")
df_submit <- df_test %>% 
  select(PassengerId, Survived) %>% 
  mutate(Survived = as.numeric(as.character(Survived)))
```

```{r}
write.csv(df_submit, "output/submit.csv", row.names = FALSE)
```



```{r}
# logit
df_test$Survived <- predict(logit, df_test, type="response")
df_submit_logit <- df_test %>% 
  mutate(Survived = if_else(Survived > 0.5, "1", "0")) %>% 
  select(PassengerId, Survived) %>% 
  mutate(Survived = as.numeric(as.character(Survived)))
```

```{r}
write.csv(df_submit_logit, "output/submit_logit.csv", row.names = FALSE)
```






